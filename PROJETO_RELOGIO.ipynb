{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9Vtht8BWdnbE9LyLgW69m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leticyadanielly/projeto1/blob/main/PROJETO_RELOGIO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b52eb804",
        "outputId": "b2bf6a52-74d9-4ad6-dfd0-8f7bb759e677"
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install scikit-learn\n",
        "!pip install numpy\n",
        "!pip install Pillow"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from PIL import Image\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# --- 1. Configuração e Carregamento do Modelo Pré-treinado ---\n",
        "# Usamos o VGG16, mas você pode experimentar com ResNet50, EfficientNet, etc.\n",
        "# 'weights=imagenet' garante que o modelo use os pesos pré-treinados.\n",
        "# 'include_top=False' remove a camada de classificação final.\n",
        "# 'pooling=avg' nos dá um vetor de características único e de tamanho fixo.\n",
        "model = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "print(\"Modelo VGG16 carregado com sucesso para extração de características.\")\n",
        "\n",
        "# --- 2. Preparação dos Dados (Simulação) ---\n",
        "# Vamos simular um diretório de imagens.\n",
        "# Crie uma pasta 'dataset' e coloque algumas imagens lá.\n",
        "# Exemplo: 'dataset/relogio1.jpg', 'dataset/relogio2.png', etc.\n",
        "dataset_path = 'dataset'\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(f\"Diretório '{dataset_path}' não encontrado. Criando um diretório de exemplo.\")\n",
        "    os.makedirs(dataset_path)\n",
        "\n",
        "\n",
        "image_files = glob.glob(os.path.join(dataset_path, '*'))\n",
        "if not image_files:\n",
        "    print(f\"--------------------------------------------------------------------\")\n",
        "    print(f\"ATENÇÃO: A pasta '{dataset_path}' está vazia.\")\n",
        "    print(f\"Por favor, adicione imagens dos produtos (e.g., relógios) na pasta '{dataset_path}'.\")\n",
        "    print(f\"Após adicionar as imagens, execute esta célula novamente.\")\n",
        "    print(f\"--------------------------------------------------------------------\")\n",
        "    # Return from the cell to stop execution without exiting the kernel\n",
        "    from google.colab.output import eval_js\n",
        "    eval_js('google.colab.kernel.restart()')\n",
        "    # Added a kernel restart to make sure the user sees the message and re-runs the cell\n",
        "    # after adding images. This is a workaround because a simple return doesn't stop execution\n",
        "    # in the middle of a cell in the same way as a direct `exit()`.\n",
        "    exit()\n",
        "\n",
        "\n",
        "print(f\"Encontradas {len(image_files)} imagens no diretório.\")\n",
        "\n",
        "# --- 3. Função para Extrair Características de uma Única Imagem ---\n",
        "def extract_features(img_path, model):\n",
        "    \"\"\"\n",
        "    Carrega, pré-processa e extrai o vetor de características de uma imagem.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(img_path).resize((224, 224)) # VGG16 espera imagens 224x224\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = preprocess_input(img_array) # Pré-processamento específico para o VGG16\n",
        "        features = model.predict(img_array, verbose=0)\n",
        "        return features.flatten() # Retorna o vetor de características como um array 1D\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao processar a imagem {img_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- 4. Extrair Características para TODO o Conjunto de Dados ---\n",
        "features_list = []\n",
        "image_names = []\n",
        "\n",
        "print(\"Extraindo características das imagens do conjunto de dados...\")\n",
        "for img_path in image_files:\n",
        "    features = extract_features(img_path, model)\n",
        "    if features is not None:\n",
        "        features_list.append(features)\n",
        "        image_names.append(os.path.basename(img_path))\n",
        "\n",
        "features_matrix = np.array(features_list)\n",
        "print(\"Extração de características concluída.\")\n",
        "print(f\"Matriz de características gerada com shape: {features_matrix.shape}\")\n",
        "\n",
        "\n",
        "# --- 5. Construção do Algoritmo de Busca de Vizinhos (KNN) ---\n",
        "# Usamos NearestNeighbors do scikit-learn, que é eficiente para encontrar os vetores mais próximos.\n",
        "# 'metric=cosine' é uma boa métrica para similaridade de vetores de características.\n",
        "# Ensure n_neighbors does not exceed the number of samples\n",
        "n_neighbors = min(5, len(image_files)) # Quantos produtos similares queremos recomendar\n",
        "if n_neighbors == 0:\n",
        "    print(\"Não há imagens para treinar o modelo KNN. Por favor, adicione imagens ao diretório 'dataset'.\")\n",
        "    # Another check and early exit if no images were processed\n",
        "    exit()\n",
        "\n",
        "nn_model = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')\n",
        "nn_model.fit(features_matrix)\n",
        "\n",
        "print(f\"Modelo de busca de vizinhos (KNN) treinado para encontrar {n_neighbors} vizinhos.\")\n",
        "\n",
        "# --- 6. Função de Recomendação (Execução) ---\n",
        "def recommend_similar_products(query_img_path, model, nn_model, image_names):\n",
        "    \"\"\"\n",
        "    Recebe o caminho de uma imagem de consulta e retorna os produtos mais similares.\n",
        "    \"\"\"\n",
        "    print(f\"\\nBuscando produtos similares para a imagem: {query_img_path}...\")\n",
        "\n",
        "    # Extrair características da imagem de consulta\n",
        "    query_features = extract_features(query_img_path, model)\n",
        "    if query_features is None:\n",
        "        return []\n",
        "\n",
        "    # Encontrar os vizinhos mais próximos no banco de dados\n",
        "    distances, indices = nn_model.kneighbors([query_features])\n",
        "\n",
        "    # Retornar os nomes dos arquivos das imagens similares\n",
        "    similar_images = [image_names[i] for i in indices[0]]\n",
        "\n",
        "    # O primeiro resultado é a própria imagem de consulta, então a removemos\n",
        "    # ou ajustamos a busca para n+1 e removemos o primeiro.\n",
        "    similar_images_filtered = [img for img in similar_images if img != os.path.basename(query_img_path)]\n",
        "\n",
        "    print(\"Recomendação concluída!\")\n",
        "    return similar_images_filtered\n",
        "\n",
        "# --- 7. Exemplo de Uso ---\n",
        "# Substitua 'dataset/imagem_de_consulta.jpg' pelo caminho de uma de suas imagens.\n",
        "if image_files: # Check if there are any images to use as a query\n",
        "  query_image_path = image_files[0]  # Usamos a primeira imagem do nosso dataset como exemplo\n",
        "  recommendations = recommend_similar_products(query_image_path, model, nn_model, image_names)\n",
        "\n",
        "  print(\"Produtos recomendados (por nome de arquivo):\")\n",
        "  for rec in recommendations:\n",
        "      print(f\"- {rec}\")\n",
        "else:\n",
        "  print(\"Não há imagens no diretório 'dataset' para executar o exemplo de uso.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m3c4mAVCRfZ",
        "outputId": "8c7fc838-13a9-491e-bb52-6abadd815d5e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo VGG16 carregado com sucesso para extração de características.\n",
            "Encontradas 3 imagens no diretório.\n",
            "Extraindo características das imagens do conjunto de dados...\n",
            "Extração de características concluída.\n",
            "Matriz de características gerada com shape: (3, 512)\n",
            "Modelo de busca de vizinhos (KNN) treinado para encontrar 3 vizinhos.\n",
            "\n",
            "Buscando produtos similares para a imagem: dataset/download.jpg...\n",
            "Recomendação concluída!\n",
            "Produtos recomendados (por nome de arquivo):\n",
            "- download (2).jpg\n",
            "- download (1).jpg\n"
          ]
        }
      ]
    }
  ]
}