{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM96b9WsxmXR+J2WgxWjwQl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leticyadanielly/projeto1/blob/main/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sceNpS3JIEpZ",
        "outputId": "f04b7faa-1d25-4a28-9e8a-03157665497b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17521, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 17521 (delta 9), reused 0 (delta 0), pack-reused 17497 (from 4)\u001b[K\n",
            "Receiving objects: 100% (17521/17521), 16.66 MiB | 24.97 MiB/s, done.\n",
            "Resolving deltas: 100% (12001/12001), done.\n",
            "/content/yolov5/yolov5/yolov5/yolov5\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.1.45)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.16.1)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
            "Requirement already satisfied: ultralytics>=8.2.64 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (8.3.175)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (75.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (2.0.15)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.2)\n",
            "✅ CUDA disponível: False\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-536086ba-2e0c-4227-b5dd-850a9359f0e2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-536086ba-2e0c-4227-b5dd-850a9359f0e2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving yolo_custom_dataset.zip to yolo_custom_dataset.zip\n",
            "Archive:  yolo_custom_dataset.zip\n",
            "  inflating: custom_dataset/data.yaml  \n",
            "  inflating: custom_dataset/images/train/image1.jpg  \n",
            "  inflating: custom_dataset/images/val/image2.jpg  \n",
            "  inflating: custom_dataset/labels/train/image1.txt  \n",
            "  inflating: custom_dataset/labels/val/image2.txt  \n",
            "✅ Dataset unzipped successfully and data.yaml found.\n",
            "🏋️ 5. Treinando com transfer learning...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "2025-08-07 01:29:35.438849: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754530175.464982    1708 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754530175.472058    1708 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1754530175.493359    1708 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754530175.493406    1708 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754530175.493411    1708 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754530175.493416    1708 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=custom_dataset/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5_custom, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-423-g567c6646 Python-3.11.13 torch-2.6.0+cu124 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 21.9MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 184MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n",
            "size\n",
            "  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...: None, 'strict': False}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/yolov5/yolov5/yolov5/custom_dataset/labels/train... 1 images, 0 backgrounds, 0 corrupt: 100% 1/1 [00:00<00:00, 18.10it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/yolov5/yolov5/yolov5/custom_dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/yolov5/yolov5/yolov5/custom_dataset/labels/val... 1 images, 0 backgrounds, 0 corrupt: 100% 1/1 [00:00<00:00, 52.49it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/yolov5/yolov5/yolov5/custom_dataset/labels/val.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.33 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/yolov5_custom/labels.jpg... \n",
            "/content/yolov5/yolov5/yolov5/yolov5/train.py:357: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolov5_custom\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/49         0G     0.1186    0.05899    0.04007          7        640: 100% 1/1 [00:06<00:00,  6.51s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.00s/it]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       1/49         0G     0.1088    0.06252     0.0489          7        640: 100% 1/1 [00:01<00:00,  1.51s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.65it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       2/49         0G      0.113    0.06301    0.04354          8        640: 100% 1/1 [00:01<00:00,  1.40s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.61it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       3/49         0G    0.07829    0.03041      0.029          2        640: 100% 1/1 [00:01<00:00,  1.42s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.68it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       4/49         0G    0.08186    0.03096    0.02523          3        640: 100% 1/1 [00:01<00:00,  1.43s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.62it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       5/49         0G     0.1101    0.09544    0.03747         12        640: 100% 1/1 [00:02<00:00,  2.10s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.38it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       6/49         0G     0.0691    0.05128    0.02493          5        640: 100% 1/1 [00:01<00:00,  1.43s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.69it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       7/49         0G    0.06678    0.03191    0.02387          2        640: 100% 1/1 [00:01<00:00,  1.43s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.63it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       8/49         0G    0.07531     0.0392    0.02529          5        640: 100% 1/1 [00:01<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.70it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       9/49         0G    0.07765      0.035    0.02292          4        640: 100% 1/1 [00:01<00:00,  1.40s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.18it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      10/49         0G     0.1125    0.08582    0.03977         12        640: 100% 1/1 [00:01<00:00,  1.59s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.67it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      11/49         0G    0.07167    0.03135    0.02645          2        640: 100% 1/1 [00:01<00:00,  1.42s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.69it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      12/49         0G     0.1101    0.08403    0.04785         10        640: 100% 1/1 [00:01<00:00,  1.39s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.71it/s]\n",
            "                   all          1          3    0.00538      0.333     0.0158    0.00158\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      13/49         0G    0.06995    0.04274    0.02456          4        640: 100% 1/1 [00:01<00:00,  1.37s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.81it/s]\n",
            "                   all          1          3    0.00565      0.333     0.0276    0.00553\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      14/49         0G    0.07121     0.0374    0.02565          3        640: 100% 1/1 [00:01<00:00,  1.80s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.16it/s]\n",
            "                   all          1          3    0.00538      0.333     0.0207    0.00622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      15/49         0G    0.07429    0.04005    0.02468          5        640: 100% 1/1 [00:01<00:00,  1.38s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.82it/s]\n",
            "                   all          1          3    0.00737      0.667      0.183     0.0218\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      16/49         0G    0.07442    0.03807    0.02703          4        640: 100% 1/1 [00:01<00:00,  1.38s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.77it/s]\n",
            "                   all          1          3    0.00521      0.333     0.0158    0.00474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      17/49         0G    0.06414    0.03707    0.02393          3        640: 100% 1/1 [00:01<00:00,  1.31s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.84it/s]\n",
            "                   all          1          3    0.00521      0.333     0.0158    0.00474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      18/49         0G     0.1098    0.05011    0.04466          5        640: 100% 1/1 [00:01<00:00,  1.41s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.82it/s]\n",
            "                   all          1          3    0.00529      0.333     0.0207    0.00622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      19/49         0G    0.06536    0.03955    0.02454          3        640: 100% 1/1 [00:01<00:00,  1.55s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.21it/s]\n",
            "                   all          1          3    0.00529      0.333     0.0207    0.00622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      20/49         0G     0.1175    0.07459    0.04026         12        640: 100% 1/1 [00:01<00:00,  1.59s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.80it/s]\n",
            "                   all          1          3    0.00476      0.333     0.0829    0.00829\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      21/49         0G    0.06976    0.04424    0.02334          5        640: 100% 1/1 [00:01<00:00,  1.31s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.78it/s]\n",
            "                   all          1          3    0.00476      0.333     0.0829    0.00829\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      22/49         0G     0.1075    0.09753    0.04085         12        640: 100% 1/1 [00:01<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.89it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      23/49         0G     0.1007    0.05004    0.03569          5        640: 100% 1/1 [00:01<00:00,  1.36s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.86it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      24/49         0G    0.06845    0.06908    0.02687          8        640: 100% 1/1 [00:01<00:00,  1.42s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.26it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      25/49         0G     0.1035    0.09137    0.04427         12        640: 100% 1/1 [00:01<00:00,  1.85s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.89it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      26/49         0G     0.1139      0.061    0.03559          6        640: 100% 1/1 [00:01<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.72it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      27/49         0G    0.06595    0.04666    0.02492          4        640: 100% 1/1 [00:01<00:00,  1.32s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.81it/s]\n",
            "                   all          1          3          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      28/49         0G    0.06603    0.03622    0.02403          3        640: 100% 1/1 [00:01<00:00,  1.41s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.72it/s]\n",
            "                   all          1          3    0.00463      0.333    0.00721   0.000721\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      29/49         0G    0.07047    0.04237    0.02512          4        640: 100% 1/1 [00:01<00:00,  1.55s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.11it/s]\n",
            "                   all          1          3    0.00463      0.333    0.00721   0.000721\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      30/49         0G     0.1131     0.0565      0.033          6        640: 100% 1/1 [00:02<00:00,  2.36s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.21it/s]\n",
            "                   all          1          3    0.00644      0.667     0.0587     0.0125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      31/49         0G    0.06539    0.04937    0.02432          5        640: 100% 1/1 [00:01<00:00,  1.35s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.72it/s]\n",
            "                   all          1          3    0.00644      0.667     0.0587     0.0125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      32/49         0G    0.07209    0.04367     0.0256          5        640: 100% 1/1 [00:01<00:00,  1.42s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.77it/s]\n",
            "                   all          1          3    0.00397      0.333     0.0369     0.0184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      33/49         0G     0.1065    0.09057    0.04344         12        640: 100% 1/1 [00:01<00:00,  1.32s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.73it/s]\n",
            "                   all          1          3    0.00397      0.333     0.0369     0.0184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      34/49         0G    0.06751    0.05721    0.02956          6        640: 100% 1/1 [00:01<00:00,  1.39s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.73it/s]\n",
            "                   all          1          3    0.00965      0.667     0.0842     0.0268\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      35/49         0G     0.0692     0.0494    0.02507          5        640: 100% 1/1 [00:01<00:00,  1.88s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.15it/s]\n",
            "                   all          1          3    0.00965      0.667     0.0842     0.0268\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      36/49         0G     0.1209    0.08421    0.03935         10        640: 100% 1/1 [00:01<00:00,  1.38s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.81it/s]\n",
            "                   all          1          3     0.0113          1     0.0801     0.0246\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      37/49         0G     0.1019    0.05157    0.03266          6        640: 100% 1/1 [00:01<00:00,  1.30s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.83it/s]\n",
            "                   all          1          3     0.0113          1     0.0801     0.0246\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      38/49         0G     0.0639    0.03739    0.02112          4        640: 100% 1/1 [00:01<00:00,  1.40s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.89it/s]\n",
            "                   all          1          3     0.0109          1      0.099     0.0265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      39/49         0G    0.06972    0.07609    0.02743          8        640: 100% 1/1 [00:01<00:00,  1.30s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.88it/s]\n",
            "                   all          1          3     0.0109          1      0.099     0.0265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      40/49         0G      0.107    0.05205    0.03631          5        640: 100% 1/1 [00:01<00:00,  1.61s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.23it/s]\n",
            "                   all          1          3     0.0107          1      0.102     0.0253\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      41/49         0G     0.1183    0.07725     0.0381          9        640: 100% 1/1 [00:01<00:00,  1.57s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.89it/s]\n",
            "                   all          1          3     0.0107          1      0.102     0.0253\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      42/49         0G    0.06257    0.04846    0.02674          4        640: 100% 1/1 [00:01<00:00,  1.40s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.86it/s]\n",
            "                   all          1          3      0.011          1     0.0774     0.0243\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      43/49         0G     0.0683    0.05957    0.02813          8        640: 100% 1/1 [00:01<00:00,  1.32s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.97it/s]\n",
            "                   all          1          3      0.011          1     0.0774     0.0243\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      44/49         0G     0.1136    0.09029    0.04989         12        640: 100% 1/1 [00:01<00:00,  1.39s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.92it/s]\n",
            "                   all          1          3    0.00904      0.667     0.0497      0.016\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      45/49         0G    0.06541    0.04434    0.02867          4        640: 100% 1/1 [00:01<00:00,  1.31s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.95it/s]\n",
            "                   all          1          3    0.00904      0.667     0.0497      0.016\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      46/49         0G    0.05094    0.04171    0.02339          3        640: 100% 1/1 [00:02<00:00,  2.02s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.72it/s]\n",
            "                   all          1          3    0.00879      0.667     0.0471     0.0158\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      47/49         0G     0.1074    0.09253    0.03868         12        640: 100% 1/1 [00:01<00:00,  1.31s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.90it/s]\n",
            "                   all          1          3    0.00879      0.667     0.0471     0.0158\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      48/49         0G    0.09552    0.07672    0.03227          8        640: 100% 1/1 [00:01<00:00,  1.40s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.91it/s]\n",
            "                   all          1          3     0.0109          1     0.0503     0.0127\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      49/49         0G    0.06697    0.04778    0.02536          5        640: 100% 1/1 [00:01<00:00,  1.36s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.80it/s]\n",
            "                   all          1          3     0.0109          1     0.0503     0.0127\n",
            "\n",
            "50 epochs completed in 0.037 hours.\n",
            "Optimizer stripped from runs/train/yolov5_custom/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/yolov5_custom/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/yolov5_custom/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.82it/s]\n",
            "                   all          1          3    0.00723      0.667      0.184     0.0221\n",
            "                   dog          1          1     0.0156          1     0.0553     0.0166\n",
            "               bicycle          1          1    0.00606          1      0.497     0.0498\n",
            "                 truck          1          1          0          0          0          0\n",
            "Results saved to \u001b[1mruns/train/yolov5_custom\u001b[0m\n",
            "🔎 6. Fazendo detecção...\n",
            "Using trained model for detection.\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/yolov5_custom/weights/best.pt'], source=custom_dataset/images/val, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_format=0, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=custom_results, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-423-g567c6646 Python-3.11.13 torch-2.6.0+cu124 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/1 /content/yolov5/yolov5/yolov5/yolov5/custom_dataset/images/val/image2.jpg: 480x640 (no detections), 292.0ms\n",
            "Speed: 2.3ms pre-process, 292.0ms inference, 0.3ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/custom_results\u001b[0m\n",
            "📸 7. Exibindo imagem com detecção...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 🚀 1. Instalar o YOLOv5 e dependências\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -r requirements.txt\n",
        "\n",
        "# 🔍 2. Verificar se há GPU\n",
        "import torch\n",
        "print('✅ CUDA disponível:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print('💻 GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# 📦 3. Fazer upload do dataset (ZIP gerado)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Envie aqui o yolo_custom_dataset.zip\n",
        "\n",
        "# 📂 4. Descompactar\n",
        "# Check if the expected zip file was uploaded\n",
        "zip_file_name = 'yolo_custom_dataset.zip'\n",
        "if zip_file_name in uploaded:\n",
        "    !unzip -o {zip_file_name}\n",
        "    # Check if the expected directory structure exists\n",
        "    import os\n",
        "    if not os.path.exists('custom_dataset/data.yaml'):\n",
        "        print(f\"Error: Expected 'custom_dataset/data.yaml' not found after unzipping.\")\n",
        "        print(\"Please ensure your zip file contains the correct directory structure:\")\n",
        "        print(\"\"\"\n",
        "        custom_dataset/\n",
        "        ├── data.yaml\n",
        "        ├── images/train/*.jpg\n",
        "        ├── images/val/*.jpg\n",
        "        └── labels/train/*.txt\n",
        "            └── labels/val/*.txt\n",
        "        \"\"\")\n",
        "    else:\n",
        "        print(\"✅ Dataset unzipped successfully and data.yaml found.\")\n",
        "\n",
        "        # 🏋️ 5. Treinar com transfer learning (usando yolov5s.pt)\n",
        "        print(\"🏋️ 5. Treinando com transfer learning...\")\n",
        "        !python train.py --img 640 --batch 16 --epochs 50 --data custom_dataset/data.yaml --weights yolov5s.pt --name yolov5_custom\n",
        "\n",
        "        # 🔎 6. Fazer detecção usando o melhor modelo treinado or default weights\n",
        "        print(\"🔎 6. Fazendo detecção...\")\n",
        "        best_model_path = 'runs/train/yolov5_custom/weights/best.pt'\n",
        "        if os.path.exists(best_model_path):\n",
        "            print(\"Using trained model for detection.\")\n",
        "            !python detect.py --weights {best_model_path} --img 640 --source custom_dataset/images/val --name custom_results\n",
        "        else:\n",
        "            print(\"Trained model not found, using default yolov5s.pt for detection.\")\n",
        "            !python detect.py --weights yolov5s.pt --img 640 --source custom_dataset/images/val --name custom_results\n",
        "\n",
        "        # 📸 7. Exibir imagem com detecção\n",
        "        print(\"📸 7. Exibindo imagem com detecção...\")\n",
        "        from IPython.display import Image, display\n",
        "        import glob\n",
        "        result_images = glob.glob('runs/detect/custom_results/*.jpg')\n",
        "        if result_images:\n",
        "            display(Image(filename=result_images[0]))\n",
        "        else:\n",
        "            print(\"No result images found in 'runs/detect/custom_results/'.\")\n",
        "\n",
        "else:\n",
        "    print(f\"Error: Expected zip file '{zip_file_name}' not found in uploaded files.\")\n",
        "    print(\"Please upload the correct zip file.\")"
      ]
    }
  ]
}